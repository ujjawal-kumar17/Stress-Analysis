{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLXVHjYstC6mNd1UTSgSmY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujjawal-kumar17/student_stress_factor_analysis./blob/main/Adult_stress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FASyuEOtmYaR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "  # Then you can read it in using pandas\n",
        "  stressAdult = pd.read_csv(fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correl = stressAdult.corr()\n",
        "plt.figure(figsize = (8,8))\n",
        "sns.heatmap(correl.iloc[:-1,-1:], annot = True, cmap = sns.color_palette(\"coolwarm\", as_cmap=True));"
      ],
      "metadata": {
        "id": "un8ict6hmj0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"There are\", len(stressAdult), \"Adult in the dataset.\")\n",
        "print(\"The avarage anxiety level is:\", round(stressAdult.anxiety_level.mean(),2))\n",
        "print(len(stress.loc[stressAdult.mental_health_history == 1]), \"Adult reported a history of mental health issues.\")"
      ],
      "metadata": {
        "id": "u8JV50p0m5zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "below_avarage = len(stressAdult.loc[stressAdult[\"self_esteem\"] < stressAdult[\"self_esteem\"].mean()])\n",
        "print(below_avarage, \"Adults have self esteem below avarage\")\n",
        "depressed = len(stressAdult.loc[stressAdult[\"depression\"] >= 10])\n",
        "print(round((depressed/len(stressAdult))*100,2), \"% of Adults reported moderate or higher levels of depression.\")"
      ],
      "metadata": {
        "id": "L7pqnzfDnCKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stressAdult.loc[stressAdult[\"headache\"] >2]), \"Adults experience headaches frequently.\")\n",
        "print(len(stressAdult.loc[stressAdult[\"sleep_quality\"] < 3]), \"Adults have bad sleep quality.\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define the mapping of category values to blood pressure values\n",
        "blood_pressure_mapping = {1: (90, 60), 2: (110, 75), 3: (130, 90)}\n",
        "\n",
        "# Create systolic and diastolic columns using map\n",
        "stressAdult['systolic'] = stressAdult['blood_pressure'].map(lambda x: blood_pressure_mapping[x][0])\n",
        "stressAdult['diastolic'] = stressAdult['blood_pressure'].map(lambda x: blood_pressure_mapping[x][1])\n",
        "\n",
        "# Calculate the mean systolic and diastolic blood pressure\n",
        "mean_systolic = stressAdult['systolic'].mean()\n",
        "mean_diastolic = stressAdult['diastolic'].mean()\n",
        "\n",
        "# Display the result\n",
        "print(\"The average blood pressure is: {}/{}\".format(round(mean_systolic, 1), round(mean_diastolic, 1)))"
      ],
      "metadata": {
        "id": "cfUibTh0n4sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stressAdult.loc[stressAdult[\"noise_level\"] >= 4]),\"Adults live in high noise level areas.\")\n",
        "print(round((len(stressAdult.loc[stressAdult[\"living_conditions\"] <= 1])/len(stressAdult))*100,2),\"% of Adults feel unsafe in their living conditions.\", sep = \"\")\n",
        "print(len(stress.loc[stressAdult[\"basic_needs\"] <= 2]),\"Adults reported, that their basic needs didn't met.\")"
      ],
      "metadata": {
        "id": "k6BQlaxIpv0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stressAdult.loc[stressAdult[\"academic_performance\"] < stressAdult[\"academic_performance\"].mean()]), \"Adults rate their academic performance below avarage.\")\n",
        "print(\"The avarage study load reported by the students is \", round(stressAdult[\"study_load\"].mean(),2),\" on a range of 0-5.\", sep = \"\")\n",
        "print(len(stressAdult.loc[stressAdult[\"future_career_concerns\"]>= 4]), \"Adults have high concerns about their future careers.\")"
      ],
      "metadata": {
        "id": "jbqZ4NL7qFdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stressAdult.loc[stressAdult[\"social_support\"]>= 2]), \"Adults feel they have strong social support.\")\n",
        "print(round((len(stressAdult.loc[stressAdult[\"bullying\"] > 0])/len(stressAdult))*100,2),\"% of Adults have experienced bullying.\", sep = \"\")\n",
        "print(f\"{len(stressAdult.loc[stressAdult['extracurricular_activities'] > 0])} Adults participate in extracurricular activities.\")"
      ],
      "metadata": {
        "id": "JCZbct24qiW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ac_perf = round(stressAdult[\"anxiety_level\"].corr(stressAdult[\"academic_performance\"]),2)\n",
        "print(\"The correlation between anxiety level and academic perofmance is \", ac_perf,\". This is a moderate negative correlation, based on this the people who think they perform better also experience less anxiety.\", sep = \"\" )\n",
        "sleep_dep = round(stressAdult[\"sleep_quality\"].corr(stressAdult[\"depression\"]),2)\n",
        "print(\"The correlation between depression and sleep quality is \", sleep_dep,\". This is a moderate/strong negative correlation, people who sleep better less likely to report higher levels of depression.\", sep = \"\")\n",
        "bull_mental = round(stressAdult[\"bullying\"].corr(stressAdult[\"mental_health_history\"]), 2)\n",
        "print(\"The correlation between bullying and history of mental illness is \",bull_mental,\". This is a moderate positive correlation, people who are the victims of bullying also more likely to have history of mental illness.\", sep = \"\")"
      ],
      "metadata": {
        "id": "mlzj9Xurs2_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the mental factor columns\n",
        "mental_pos = stress[[\"anxiety_level\", \"depression\", \"self_esteem\", \"mental_health_history\"]]\n",
        "#Create a dictionary\n",
        "mental_pos_count = {}\n",
        "#Iterate over the pyschological factor columns\n",
        "for column,row in mental_pos.items():\n",
        "    #If it is anxiety or depression we count the people who are in the upper 40%\n",
        "    if column == \"anxiety_level\" or column == \"depression\":\n",
        "        count = (row > np.percentile(mental_pos[column],60))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        mental_pos_count[column] = count\n",
        "    #Everyone who had history with mental diseases get counted\n",
        "    elif column == \"mental_health_history\":\n",
        "        count = row == 1\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        mental_pos_count[column] = count\n",
        "    #People who are in the lower 40% get counted for self-esteem\n",
        "    else:\n",
        "        count = (row < np.percentile(mental_pos[column],40))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        mental_pos_count[column] = count\n",
        "#Create a pandas dataframe\n",
        "mental_pos_df = pd.DataFrame(mental_pos_count)\n",
        "#Count every row where atleast one value is true\n",
        "mental_number = len((mental_pos_df[(mental_pos_df >= 1).sum(axis=1) >= 1]))"
      ],
      "metadata": {
        "id": "fJCYf8P6BzyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the physical factor columns\n",
        "physical = stress[[\"headache\", \"blood_pressure\", \"sleep_quality\", \"breathing_problem\"]]\n",
        "#Create a dictionary\n",
        "physical_dict = {}\n",
        "#Iterate over the physical factor columns\n",
        "for column,row in physical.items():\n",
        "    #People in the upper 40% for headache, breathing problems or blood pressure get counted\n",
        "    if column == \"headache\" or column == \"breathing problem\" or column == \"blood_pressure\":\n",
        "        count = (row > np.percentile(physical[column],60))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        physical_dict[column] = count\n",
        "    #People in the lower 40% for sleep quality get counted\n",
        "    else:\n",
        "        count = (row < np.percentile(physical[column],40))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        physical_dict[column] = count\n",
        "#Create a pandas dataframe\n",
        "physical_df = pd.DataFrame(physical_dict)\n",
        "#Count every row where atleast one value is true\n",
        "physical_number = len((physical_df[(physical_df >= 1).sum(axis=1) >= 1]))"
      ],
      "metadata": {
        "id": "1DuhjjwCB2wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the environmental factor columns\n",
        "env = stress[[\"living_conditions\", \"safety\", \"basic_needs\", \"noise_level\"]]\n",
        "#Create a dictionary\n",
        "env_dict = {}\n",
        "#Iterate over the environmental factor columns\n",
        "for column,row in env.items():\n",
        "    #People in the upper 40% for noise level get counted\n",
        "    if column == \"noise_level\":\n",
        "        count = (row > np.percentile(env[column],60))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        env_dict[column] = count\n",
        "    #People in the lower 40% for sleep quality get counted\n",
        "    else:\n",
        "        count = (row < np.percentile(env[column],40))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        env_dict[column] = count\n",
        "#Create a pandas dataframe\n",
        "env_df = pd.DataFrame(env_dict)\n",
        "#Count every row where atleast one value is true\n",
        "env_number = len((env_df[(env_df >= 1).sum(axis=1) >= 1]))"
      ],
      "metadata": {
        "id": "lshfRJy4B6Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the academic factor columns\n",
        "acad = stress[[\"academic_performance\", \"study_load\", \"teacher_student_relationship\", \"future_career_concerns\"]]\n",
        "#Create a dictionary\n",
        "acad_dict = {}\n",
        "#Iterate over the academic factor columns\n",
        "for column,row in acad.items():\n",
        "    #People in the upper 40% for study load and future career concners get counted\n",
        "    if column == \"study_load\" or column == \"future_career_concerns\":\n",
        "        count = (row > np.percentile(acad[column],60))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        acad_dict[column] = count\n",
        "    #People in the lower 40% for academic performance or teacher student relationship get counted\n",
        "    else:\n",
        "        count = (row < np.percentile(acad[column],40))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        acad_dict[column] = count\n",
        "#Create a pandas dataframe\n",
        "acad_df = pd.DataFrame(acad_dict)\n",
        "#Count every row where atleast one value is true\n",
        "acad_number = len((acad_df[(acad_df >= 1).sum(axis=1) >= 1]))"
      ],
      "metadata": {
        "id": "-nFXOPLwB_j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate the social factor columns\n",
        "social = stress.iloc[:, 16:20]\n",
        "#Create a dictionary\n",
        "social_dict = {}\n",
        "#Iterate over the academic factor columns\n",
        "for column,row in social.items():\n",
        "    #People in the upper 40% for peer pressure, extracurricular activities and bullying get counted\n",
        "    if column == \"peer_pressure\" or column == \"extracurricular_activities\" or column == \"bullying\":\n",
        "        count = (row > np.percentile(social[column],60))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        social_dict[column] = count\n",
        "    #People in the lower 40% for social support get counted\n",
        "    else:\n",
        "        count = (row < np.percentile(social[column],40))\n",
        "        #Add the resulting dataset to the dictionary under the column's name\n",
        "        social_dict[column] = count\n",
        "#Create a pandas dataframe\n",
        "social_df = pd.DataFrame(social_dict)\n",
        "#Count every row where atleast one value is true\n",
        "social_number = len((social_df[(social_df >= 1).sum(axis=1) >= 1]))"
      ],
      "metadata": {
        "id": "BLfPmNAdCChv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a pandas series from the numbers\n",
        "neg = pd.Series([mental_number, physical_number, env_number, acad_number, social_number])\n",
        "#Choose column names\n",
        "col_names = [\"Mental\", \"Physical\", \"Environmental\", \"Academic\", \"Social\"]\n",
        "#Create the barplot\n",
        "ax = sns.barplot(x = col_names, y = neg.values)\n",
        "#Name the plot\n",
        "ax.set(title=\"Number of students with negative experiences in the different fields\")\n",
        "#Show the number on top of the bar\n",
        "ax.bar_label(ax.containers[0])\n",
        "#Set the y label\n",
        "ax.set_ylabel(\"Number of students\");"
      ],
      "metadata": {
        "id": "Iu2JSohnCE9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose which factor has the biggest impact on stress level within each variable subgroup.\n",
        "print(\"In mental variables\", round(correl.iloc[-1:,0:4].abs().max(),2).index.max().replace(\"_\", \" \"), \"has the biggest impact.\")\n",
        "print(\"In physical variables\", round(correl.iloc[-1:,4:8].abs().max(),2).index.max().replace(\"_\", \" \"), \"has the biggest impact.\")\n",
        "print(\"In environmental variables\", round(correl.iloc[-1:,8:12].abs().max(),2).index.max()), \"has the biggest impact.\"\n",
        "print(\"In academic variables\", round(correl.iloc[-1:,12:16].abs().max(),2).index.max().replace(\"_\", \" \"), \"has the biggest impact.\")\n",
        "print(\"In social variables\", round(correl.iloc[-1:,16:20].abs().max(),2).index.max().replace(\"_\", \" \"), \"has the biggest impact.\")"
      ],
      "metadata": {
        "id": "yqJ9f44rCGAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stress.isnull().sum()"
      ],
      "metadata": {
        "id": "91swBwIHCRv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Selecting features\n",
        "selected_features = stress.columns[:-1]  # Exclude the 'stress_level'\n",
        "\n",
        "# Setting up subplots\n",
        "fig, axes = plt.subplots(7, 3, figsize=(15, 20))\n",
        "fig.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# Plotting bar charts for each feature\n",
        "for i, feature in enumerate(selected_features):\n",
        "    if i < 21:  # Limit the number of subplots to the available space\n",
        "        row, col = divmod(i, 3)\n",
        "        ax = axes[row, col]\n",
        "        stress[feature].value_counts().sort_index().plot(kind='bar', ax=ax)\n",
        "        ax.set_title(feature)\n",
        "        ax.set_xlabel('Value')\n",
        "        ax.set_ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ayaedcCfCSm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "stress['stress_level'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, colors=['lightblue', 'lightgreen', 'lightcoral'])\n",
        "plt.title('Distribution of Stress Levels')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vPlJhj2nCapO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = stress.columns[:-1]  # Exclude the 'stress_level' column\n",
        "\n",
        "statistics = stress[selected_features].describe().transpose()\n",
        "\n",
        "# Adding skewness and kurtosis to the statistics\n",
        "statistics['skewness'] = stress[selected_features].skew()\n",
        "statistics['kurtosis'] = stress[selected_features].kurt()\n",
        "print(statistics)"
      ],
      "metadata": {
        "id": "y7_1RT8_Cc5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "correlation_matrix = stress[['stress_level', 'anxiety_level', 'self_esteem', 'depression', 'sleep_quality', 'extracurricular_activities']].corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2yQi14HWCgeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of features to create box plots for\n",
        "features = ['anxiety_level', 'self_esteem', 'mental_health_history', 'depression']\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
        "\n",
        "# Loop through features and create box plots\n",
        "for i, feature in enumerate(features):\n",
        "    row, col = divmod(i, 2)  # divmod returns quotient and remainder\n",
        "    sns.boxplot(x=stress[feature], ax=axes[row, col], color='skyblue')\n",
        "    axes[row, col].set_title(feature.replace('_', ' ').title())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6t7p5h5eCovx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create categorical variables from numerical data\n",
        "k_bins = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
        "categorical_data = pd.DataFrame(k_bins.fit_transform(stress), columns=stress.columns)\n",
        "\n",
        "# Perform a chi-square test\n",
        "chi2_results = {}\n",
        "for column in categorical_data.columns:\n",
        "    contingency_table = pd.crosstab(categorical_data[column], stress['stress_level'])\n",
        "    chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
        "    chi2_results[column] = {'Chi2 Statistic': chi2_stat, 'p-value': p_value}\n",
        "\n",
        "chi2_results_stress = pd.DataFrame(chi2_results).T\n",
        "\n",
        "print(\"\\nchi2_results:\")\n",
        "print(chi2_results_stress)"
      ],
      "metadata": {
        "id": "r92MWSyyCxMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = stress.columns[:-1]  # Exclude the 'stress_level' column\n",
        "\n",
        "# Covariance matrix\n",
        "cov_matrix = stress[selected_features].cov()\n",
        "\n",
        "plt.figure(figsize=(9, 5))\n",
        "plt.imshow(cov_matrix, cmap='viridis', interpolation='none')\n",
        "plt.colorbar(label='Covariance')\n",
        "plt.xticks(range(len(selected_features)), selected_features, rotation=45)\n",
        "plt.yticks(range(len(selected_features)), selected_features)\n",
        "plt.title('Covariance Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wwrt7VtaDnLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import f_oneway\n",
        "# ANOVA\n",
        "categorical_variable = 'academic_performance'\n",
        "\n",
        "anova_results = {}\n",
        "for continuous_variable in selected_features:\n",
        "    if continuous_variable != categorical_variable:\n",
        "        group_data = [stress[stress[categorical_variable] == group][continuous_variable] for group in stress[categorical_variable].unique()]\n",
        "        f_stat, p_value = f_oneway(*group_data)\n",
        "        anova_results[continuous_variable] = {'F-statistic': f_stat, 'p-value': p_value}\n",
        "\n",
        "anova_stress = pd.DataFrame(anova_results).T\n",
        "\n",
        "# Displaying ANOVA results\n",
        "print(\"\\nANOVA results:\")\n",
        "print(anova_stress)"
      ],
      "metadata": {
        "id": "gmdJmmWKDyoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore, norm\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "# Specify the variable for which you want to perform the Z-test\n",
        "Target = 'anxiety_level'\n",
        "\n",
        "# Extract the data for the specific category of 'academic_performance'\n",
        "category_data = stress[stress['academic_performance'] == 1][Target]\n",
        "\n",
        "# Calculate the Z-scores\n",
        "z_scores = zscore(category_data)\n",
        "\n",
        "# Define the significance level (e.g., 0.05)\n",
        "alpha = 0.05\n",
        "\n",
        "# Calculate the critical Z-value for a two-tailed test\n",
        "critical_z = norm.ppf(1 - alpha / 2)\n",
        "\n",
        "# Calculate the test statistic\n",
        "test_statistic = z_scores.mean()\n",
        "\n",
        "# Compare the test statistic to the critical Z-value\n",
        "if np.abs(test_statistic) > critical_z:\n",
        "    print(f\"The Z-test result is statistically significant for {Target} in academic performance.\")\n",
        "else:\n",
        "    print(f\"The Z-test result is not statistically significant for {Target} in academic performance.\")\n",
        "\n",
        "# Calculate the p-values for each Z-score\n",
        "p_values = 2 * (1 - stats.norm.cdf(np.abs(z_scores)))\n",
        "# Hypothesis testing for each p-value\n",
        "if any(p_values < alpha):\n",
        "    print(\"Reject Null Hypothesis for at least one observation.\")\n",
        "else:\n",
        "    print(\"Fail to Reject Null Hypothesis for all observations.\")"
      ],
      "metadata": {
        "id": "9xxajMIpEulL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as pex\n",
        "import warnings\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda\n",
        "import pandas as pd\n",
        "\n",
        "# Suppressing the FutureWarning\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
        "\n",
        "\n",
        "    model = lda(n_components=1)\n",
        "    newData = model.fit_transform(stress.drop('stress_level', axis=1), stress['stress_level'])\n",
        "\n",
        "# Creating a DataFrame with meaningful column names\n",
        "newData = pd.DataFrame({'LD1': newData[:, 0], 'stress_level': stress['stress_level'], 'y': 0})\n",
        "model.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "oJ47x6biFAEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = pex.scatter(newData, x='LD1', y='y', color='stress_level',\n",
        "                  color_continuous_scale=pex.colors.sequential.Viridis,title='LDA - Scatter Plot')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "wJV0tgOiFFga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_matrix = np.cov(stress.drop('stress_level',axis=1), rowvar=False)\n",
        "cov_matrix.shape\n",
        "(30, 30)\n",
        "values, vectors = np.linalg.eig(cov_matrix)\n",
        "print(\"Values shape: \" + str(values.shape))\n",
        "print(\"Vectors shape: \" + str(vectors.shape))"
      ],
      "metadata": {
        "id": "cWORQGmFFvMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4),dpi=100)\n",
        "plt.plot(values,marker='s',color='red',lw=1)\n",
        "plt.xlabel('Number corresponding to each Eigenvalue')\n",
        "plt.ylabel('Variance')\n",
        "plt.title('Variances for Each Axis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DSVU7hj2F0oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Take the top 3 eigenvectors and project data onto them.\n",
        "top_3_vectors = vectors[:,np.array([0,1,2])]\n",
        "# Project data down to 3 axes by computing dot product\n",
        "principal_comp = np.dot(stress.drop('stress_level',axis=1).values, top_3_vectors)\n",
        "print(principal_comp.shape) #Correct shape"
      ],
      "metadata": {
        "id": "iwAvPOd_F5W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pex.scatter_3d(x=principal_comp[:,0],y=principal_comp[:,1],z=principal_comp[:,2],color=stress.stress_level, color_continuous_scale=pex.colors.sequential.Viridis)"
      ],
      "metadata": {
        "id": "RQ34UxEzF6DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "scaler = StandardScaler()\n",
        "stress_standardized = scaler.fit_transform(stress)\n",
        "#stress_normalized = scaler.fit_transform(X)\n",
        "U, S, Vt = np.linalg.svd(stress, full_matrices=False)\n",
        "# Calculate the explained variance\n",
        "explained_variance = np.cumsum(S**2) / np.sum(S**2)\n",
        "\n",
        "# Choose the number of components to retain\n",
        "n_components = np.argmax(explained_variance > 0.95) + 1\n",
        "U_reduced = U[:, :n_components]\n",
        "S_reduced = np.diag(S[:n_components])\n",
        "Vt_reduced = Vt[:n_components, :]\n"
      ],
      "metadata": {
        "id": "LbWEcM1GF_jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stress_reduced = np.dot(U_reduced, np.dot(S_reduced, Vt_reduced))\n",
        "svd = TruncatedSVD(n_components=2)\n",
        "stress_reduced_sklearn = svd.fit_transform(stress)"
      ],
      "metadata": {
        "id": "kiJrLqv-GBpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Assuming explained_variance is calculated as in the previous example\n",
        "\n",
        "# Create a scree plot\n",
        "trace1 = go.Scatter(\n",
        "    x=list(range(1, len(explained_variance) + 1)),\n",
        "    y=explained_variance,\n",
        "    mode='lines+markers',\n",
        "    name='Explained Variance',\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    title='Scree Plot of Explained Variance',\n",
        "    xaxis=dict(title='Principal Component'),\n",
        "    yaxis=dict(title='Explained Variance'),\n",
        ")\n",
        "\n",
        "fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'scatter'}]])\n",
        "fig.add_trace(trace1)\n",
        "fig.update_layout(layout)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "axRa75FLGEJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgmpy"
      ],
      "metadata": {
        "id": "Csg3IDTXGGPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from pgmpy.estimators import ParameterEstimator, MaximumLikelihoodEstimator\n",
        "from pgmpy.models import BayesianModel\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data Splitting\n",
        "X = stress.drop([\"stress_level\"], axis=1)\n",
        "y = stress.stress_level\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Scaling with StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
        "    X_train_scaled = scaler.transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Gz5PSOcKGUCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "5wOEa6oEGZWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc"
      ],
      "metadata": {
        "id": "LdzK9ivUGcKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "\n",
        "# Step 2: Train the model on the training set\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Make predictions on the testing set\n",
        "y_pred = dt_model.predict(X_test)\n",
        "\n",
        "# Step 4: Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "id": "wXZNxJTLGePc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize the labels for each class\n",
        "y_test_bin = label_binarize(y_test, classes=dt_model.classes_)\n",
        "\n",
        "y_pred_prob = dt_model.predict_proba(X_test)\n",
        "\n",
        "# Calculate ROC curve for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(len(dt_model.classes_)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curves for each class\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(len(dt_model.classes_)):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve - Multiclass')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TpRHdj_9GsdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = LinearDiscriminantAnalysis()\n",
        "\n",
        "# Step 3: Train the model on the training set\n",
        "lda_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the testing set\n",
        "y_pred = lda_model.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Step 6: Print the results\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "id": "4u7gLrfXG0yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_components = 3\n",
        "pca = PCA(n_components=n_components)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Step 4: Train a classifier (Random Forest in this example) on the PCA-transformed data\n",
        "classifier = RandomForestClassifier(random_state=42)\n",
        "classifier.fit(X_train_pca, y_train)\n",
        "\n",
        "# Step 5: Make predictions on the testing set\n",
        "y_pred = classifier.predict(X_test_pca)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Step 7: Print the results\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "id": "oKS16_WTG1f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# List of distance metrics\n",
        "distance_metrics = ['euclidean', 'manhattan', 'hamming', 'cosine']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, metric in enumerate(distance_metrics):\n",
        "    # K-Nearest Neighbors (KNN) with GridSearchCV for each distance metric\n",
        "    param_grid_knn = {'n_neighbors': [1, 2, 3, 5, 6, 7, 9, 11, 13], 'weights': ['uniform', 'distance']}\n",
        "    knn = KNeighborsClassifier(metric=metric)\n",
        "    grid_search_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='accuracy', return_train_score=False, verbose=1)\n",
        "    grid_search_knn.fit(X_train_scaled, y_train)\n",
        "    y_pred_knn = grid_search_knn.predict(X_test_scaled)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = metrics.confusion_matrix(y_test, y_pred_knn)\n",
        "\n",
        "    # Plot confusion matrix using Seaborn\n",
        "    ax = axes[i]\n",
        "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', ax=ax)\n",
        "    ax.set_title(f'Confusion Matrix - {metric} distance')\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t7F9Iv63G4DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for metric in distance_metrics:\n",
        "    # Initialize the KNN classifier with the specified distance metric\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=3, metric=metric)\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nResults for {metric} distance:\")\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\")"
      ],
      "metadata": {
        "id": "RU8NP2OxHB4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize the labels for each class\n",
        "y_test_bin = label_binarize(y_test, classes=dt_model.classes_)\n",
        "\n",
        "y_pred_prob = dt_model.predict_proba(X_test)\n",
        "\n",
        "# Calculate ROC curve for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(len(dt_model.classes_)):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curves for each class\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(len(dt_model.classes_)):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve - Multiclass')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WMnWRoWdHFds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "num_classes = len(set(y))\n",
        "\n",
        "# Neural Network Architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "model.fit(X_train, tf.keras.utils.to_categorical(y_train, num_classes=num_classes), epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the Model\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert true labels to one-hot encoding\n",
        "y_test_one_hot = label_binarize(y_test, classes=range(num_classes))\n",
        "\n",
        "# Calculate accuracy\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy*100}\")\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate with classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "id": "HYtz_cf_HKEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ROC curve for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_one_hot[:, i], y_pred_prob[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Plot ROC curves for each class\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(num_classes):\n",
        "    plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve - Multiclass')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "05RJ-rAbHM89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3bypt9lHN2g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}